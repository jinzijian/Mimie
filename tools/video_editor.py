import os
import json
import google.generativeai as genai
from dotenv import load_dotenv
from openai import OpenAI
import ffmpeg
from typing import List, Dict, Any,Optional
from utils.project_organizer import ProjectOrganizer
from core.call_llms import call_gemini, call_openai, call_anthropic
try:
    from tools.base_tool import Tool
except ModuleNotFoundError:  # pragma: no cover
    import sys as _sys
    from pathlib import Path as _Path
    _repo_root = _Path(__file__).resolve().parents[1]
    if str(_repo_root) not in _sys.path:
        _sys.path.append(str(_repo_root))
    from tools.base_tool import Tool
from video_understander import understand_video_for_editor

load_dotenv()


class VideoClipExtractor(Tool):
    """ä»Žè§†é¢‘æ–‡ä»¶ä¸­æå–å•ä¸ªæŒ‡å®šç‰‡æ®µçš„å·¥å…·"""
    
    name: str = "video_clip_extractor"
    description: str = "Extract a single clip from a video file within a specified time range"
    parameters: dict = {
        "type": "object",
        "required": ["asset_path", "start_time", "end_time"],
        "properties": {
            "asset_path": {
                "type": "string",
                "description": "The path to the source video file",
            },
            "start_time": {
                "type": "number",
                "description": "The start time (in seconds)",
            },
            "end_time": {
                "type": "number",
                "description": "The end time (in seconds)",
            },
            "clip_name": {
                "type": "string",
                "description": "Custom clip name, if not provided, it will be generated automatically",
            }
        },
    }

    def execute(self, asset_path: str, start_time: float, end_time: float, 
                clip_name: Optional[str] = None) -> str:
        """
        æå–è§†é¢‘ç‰‡æ®µ
        
        Args:
            asset_path: æºè§†é¢‘æ–‡ä»¶è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
            clip_name: è‡ªå®šä¹‰ç‰‡æ®µåç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æå–å‡ºçš„ç‰‡æ®µæ–‡ä»¶è·¯å¾„
        """
        try:
            print(f"ðŸ” æå–ç‰‡æ®µ: {os.path.basename(asset_path)}")
            print(f"   æ—¶é—´èŒƒå›´: {start_time}s - {end_time}s")
            
            # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(asset_path):
                error_msg = f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {asset_path}"
                print(error_msg)
                return error_msg
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if clip_name is None:
                base_name = os.path.splitext(os.path.basename(asset_path))[0]
                clip_name = f"extracted_{base_name}"
            
            output_path = f"{ProjectOrganizer.get_save_dir(ProjectOrganizer.SaveType.ASSETS)}{clip_name}.mp4"
            duration = end_time - start_time
            
            print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
            print(f"   ç‰‡æ®µæ—¶é•¿: {duration:.1f}s")
            
            # ä½¿ç”¨ffmpegæå–ç‰‡æ®µ
            input_stream = ffmpeg.input(asset_path, ss=start_time, t=duration)
            output_stream = ffmpeg.output(
                input_stream, 
                output_path,
                vcodec='libx264',
                acodec='aac',
                preset='medium',
                crf=23,
                pix_fmt='yuv420p'
            )
            
            ffmpeg.run(output_stream, overwrite_output=True, quiet=True)
            
            # æ£€æŸ¥è¾“å‡ºç»“æžœ
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024 * 1024)
                print(f"   âœ… æå–æˆåŠŸ ({file_size:.1f} MB)")
                return output_path
            else:
                error_msg = "âŒ æå–å¤±è´¥ï¼Œæ–‡ä»¶æœªåˆ›å»º"
                print(error_msg)
                return error_msg
                        
        except Exception as e:
            error_msg = f"âŒ æå–å¤±è´¥: {str(e)}"
            print(error_msg)
            return error_msg

class VideoConcatenator(Tool):
    """è§†é¢‘æ‹¼æŽ¥å·¥å…·"""
    
    name: str = "video_concatenator"
    description: str = "Concatenate multiple video clips into a complete video"
    parameters: dict = {
        "type": "object",
        "required": ["clip_paths"],
        "properties": {
            "clip_paths": {
                "type": "string",
                "description": "The array of video clip file paths, JSON format string, e.g.: [\"path1.mp4\", \"path2.mp4\"]",
            }
        },
    }

    def _get_video_info(self, video_path: str) -> Dict[str, Any]:
        """
        èŽ·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯
        
        Returns:
            dict: åŒ…å«è§†é¢‘ä¿¡æ¯
        """
        result = {
            'valid': False,
            'has_video': False,
            'has_audio': False,
            'duration': 0,
            'width': 0,
            'height': 0,
            'fps': 0,
            'error': None,
            'file_size_mb': 0
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                result['error'] = "æ–‡ä»¶ä¸å­˜åœ¨"
                return result
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(video_path)
            if file_size == 0:
                result['error'] = "æ–‡ä»¶ä¸ºç©º"
                return result
            
            result['file_size_mb'] = file_size / (1024 * 1024)
            
            # ä½¿ç”¨ffprobeæ£€æŸ¥è§†é¢‘æ–‡ä»¶
            probe = ffmpeg.probe(video_path)
            
            # æ£€æŸ¥æµä¿¡æ¯
            streams = probe.get('streams', [])
            if not streams:
                result['error'] = "æ–‡ä»¶æ²¡æœ‰åª’ä½“æµ"
                return result
            
            # æ£€æŸ¥è§†é¢‘å’ŒéŸ³é¢‘æµ
            for stream in streams:
                codec_type = stream.get('codec_type', '')
                if codec_type == 'video':
                    result['has_video'] = True
                    result['width'] = stream.get('width', 0)
                    result['height'] = stream.get('height', 0)
                    
                    # èŽ·å–å¸§çŽ‡
                    r_frame_rate = stream.get('r_frame_rate', '0/1')
                    if '/' in r_frame_rate:
                        num, den = r_frame_rate.split('/')
                        if int(den) != 0:
                            result['fps'] = int(num) / int(den)
                    
                    # èŽ·å–æ—¶é•¿
                    if 'duration' in stream:
                        result['duration'] = float(stream['duration'])
                        
                elif codec_type == 'audio':
                    result['has_audio'] = True
            
            # å¦‚æžœæ²¡æœ‰ä»Žæµä¸­èŽ·å–åˆ°æ—¶é•¿ï¼Œå°è¯•ä»Žformatä¸­èŽ·å–
            if result['duration'] == 0 and 'format' in probe:
                format_info = probe['format']
                if 'duration' in format_info:
                    result['duration'] = float(format_info['duration'])
            
            # å¿…é¡»æœ‰è§†é¢‘æµæ‰ç®—æœ‰æ•ˆ
            if result['has_video']:
                result['valid'] = True
            else:
                result['error'] = "æ–‡ä»¶æ²¡æœ‰è§†é¢‘æµ"
                
        except ffmpeg.Error as e:
            result['error'] = f"ffprobeé”™è¯¯: {str(e)}"
        except Exception as e:
            result['error'] = f"éªŒè¯å¤±è´¥: {str(e)}"
            
        return result

    def _determine_target_resolution(self, video_files: List[Dict]) -> tuple[int, int]:
        """
        ç¡®å®šç›®æ ‡åˆ†è¾¨çŽ‡
        é€‰æ‹©æœ€å¸¸è§çš„åˆ†è¾¨çŽ‡ï¼Œæˆ–è€…æœ€é«˜çš„åˆ†è¾¨çŽ‡
        """
        resolutions = {}
        max_pixels = 0
        best_resolution = (1920, 1080)  # é»˜è®¤åˆ†è¾¨çŽ‡
        
        for video in video_files:
            width, height = video['width'], video['height']
            resolution = (width, height)
            pixels = width * height
            
            # ç»Ÿè®¡åˆ†è¾¨çŽ‡å‡ºçŽ°æ¬¡æ•°
            if resolution in resolutions:
                resolutions[resolution] += 1
            else:
                resolutions[resolution] = 1
            
            # è®°å½•æœ€é«˜åˆ†è¾¨çŽ‡
            if pixels > max_pixels:
                max_pixels = pixels
                best_resolution = resolution
        
        # é€‰æ‹©å‡ºçŽ°æ¬¡æ•°æœ€å¤šçš„åˆ†è¾¨çŽ‡
        most_common_resolution = max(resolutions.items(), key=lambda x: x[1])[0]
        
        print(f"ðŸŽ¯ åˆ†è¾¨çŽ‡ç»Ÿè®¡: {resolutions}")
        print(f"ðŸ“ é€‰æ‹©ç›®æ ‡åˆ†è¾¨çŽ‡: {most_common_resolution[0]}x{most_common_resolution[1]}")
        
        return most_common_resolution

    def execute(self, clip_paths: str) -> str:
        """
        æ‹¼æŽ¥è§†é¢‘ç‰‡æ®µ
        
        Args:
            clip_paths: è§†é¢‘ç‰‡æ®µæ–‡ä»¶è·¯å¾„æ•°ç»„çš„JSONå­—ç¬¦ä¸²
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ‹¼æŽ¥å®Œæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æžœå¤±è´¥åˆ™è¿”å›žé”™è¯¯ä¿¡æ¯
        """
        output_path = f"{ProjectOrganizer.get_save_dir(ProjectOrganizer.SaveType.ASSETS)}concatenated_video.mp4"
        
        try:
            print(f"ðŸ”— å¼€å§‹æ‹¼æŽ¥è§†é¢‘...")
            
            # è§£æžç‰‡æ®µè·¯å¾„æ•°ç»„
            try:
                video_files = json.loads(clip_paths)
                if not isinstance(video_files, list):
                    error_msg = "âŒ clip_pathså¿…é¡»æ˜¯æ•°ç»„æ ¼å¼çš„JSONå­—ç¬¦ä¸²"
                    print(error_msg)
                    return error_msg
            except json.JSONDecodeError as e:
                error_msg = f"âŒ JSONè§£æžå¤±è´¥: {e}"
                print(error_msg)
                return error_msg
            
            print(f"ðŸŽ¬ å¾…æ‹¼æŽ¥ç‰‡æ®µæ•°é‡: {len(video_files)}")
            
            if not video_files:
                error_msg = "âŒ æ²¡æœ‰æä¾›è§†é¢‘ç‰‡æ®µ"
                print(error_msg)
                return error_msg
            
            # éªŒè¯æ‰€æœ‰è¾“å…¥æ–‡ä»¶
            valid_files = []
            skipped_files = []
            total_duration = 0
            
            for i, video_path in enumerate(video_files):
                print(f"ðŸ” éªŒè¯ç‰‡æ®µ {i+1}: {os.path.basename(video_path)}")
                
                video_info = self._get_video_info(video_path)
                
                if video_info['valid']:
                    print(f"   âœ… æ–‡ä»¶æœ‰æ•ˆ ({video_info['file_size_mb']:.1f} MB, {video_info['duration']:.1f}s)")
                    print(f"   ðŸ“¹ åˆ†è¾¨çŽ‡: {video_info['width']}x{video_info['height']}")
                    print(f"   ðŸ”Š éŸ³é¢‘æµ: {'æ˜¯' if video_info['has_audio'] else 'å¦'}")
                    valid_files.append({
                        'path': video_path,
                        'has_audio': video_info['has_audio'],
                        'duration': video_info['duration'],
                        'width': video_info['width'],
                        'height': video_info['height'],
                        'fps': video_info['fps']
                    })
                    total_duration += video_info['duration']
                else:
                    print(f"   âŒ æ–‡ä»¶æ— æ•ˆ: {video_info['error']}")
                    skipped_files.append({
                        'path': video_path,
                        'reason': video_info['error']
                    })
            
            if not valid_files:
                error_msg = "âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶"
                print(error_msg)
                if skipped_files:
                    print("è·³è¿‡çš„æ–‡ä»¶:")
                    for skipped in skipped_files:
                        print(f"   - {os.path.basename(skipped['path'])}: {skipped['reason']}")
                return error_msg
            
            print(f"ðŸ“Š æœ‰æ•ˆæ–‡ä»¶: {len(valid_files)} ä¸ª")
            print(f"ðŸ“Š è·³è¿‡æ–‡ä»¶: {len(skipped_files)} ä¸ª")
            print(f"â±ï¸  é¢„è®¡æ€»æ—¶é•¿: {total_duration:.1f} ç§’")
            
            if skipped_files:
                print("âš ï¸  è·³è¿‡çš„æ–‡ä»¶:")
                for skipped in skipped_files:
                    print(f"   - {os.path.basename(skipped['path'])}: {skipped['reason']}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # æ‹¼æŽ¥è§†é¢‘
            success, error_detail = self._concat_videos(valid_files, output_path)
            
            if not success:
                error_msg = f"âŒ æ‹¼æŽ¥è¿‡ç¨‹å¤±è´¥: {error_detail}"
                print(error_msg)
                return error_msg
            
            # æ£€æŸ¥è¾“å‡ºç»“æžœ
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024 * 1024)
                
                # èŽ·å–æœ€ç»ˆè§†é¢‘æ—¶é•¿
                try:
                    probe = ffmpeg.probe(output_path)
                    duration = float(probe['streams'][0]['duration'])
                except:
                    duration = 0
                
                print(f"âœ… è§†é¢‘æ‹¼æŽ¥æˆåŠŸ")
                print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
                print(f"   æœ‰æ•ˆç‰‡æ®µ: {len(valid_files)}")
                print(f"   è·³è¿‡ç‰‡æ®µ: {len(skipped_files)}")
                print(f"   æ€»æ—¶é•¿: {duration:.1f} ç§’")
                print(f"   æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
                
                return output_path
            else:
                error_msg = "âŒ æ‹¼æŽ¥å¤±è´¥ï¼Œè¾“å‡ºæ–‡ä»¶æœªåˆ›å»º"
                print(error_msg)
                return error_msg
                
        except Exception as e:
            error_msg = f"âŒ æ‹¼æŽ¥å¤±è´¥: {str(e)}"
            print(error_msg)
            return error_msg
    
    def _concat_videos(self, video_files: List[Dict], output_path: str) -> tuple[bool, str]:
        """
        æ‹¼æŽ¥å¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå¤„ç†åˆ†è¾¨çŽ‡ä¸åŒ¹é…é—®é¢˜
        
        Args:
            video_files: åŒ…å«è§†é¢‘æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            tuple: (æ˜¯å¦æˆåŠŸ, é”™è¯¯è¯¦æƒ…)
        """
        try:
            print(f"ðŸ”— å¼€å§‹æ‹¼æŽ¥ {len(video_files)} ä¸ªæ–‡ä»¶...")
            
            if len(video_files) == 1:
                # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æŽ¥å¤åˆ¶
                import shutil
                print("ðŸ“‹ åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æŽ¥å¤åˆ¶...")
                shutil.copy2(video_files[0]['path'], output_path)
                print("âœ… å¤åˆ¶å®Œæˆ")
                return True, ""
            
            # å¤šä¸ªæ–‡ä»¶éœ€è¦æ‹¼æŽ¥
            print("ðŸŽ¬ å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ffmpegæ‹¼æŽ¥...")
            
            # ç¡®å®šç›®æ ‡åˆ†è¾¨çŽ‡
            target_width, target_height = self._determine_target_resolution(video_files)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰éŸ³é¢‘æµ
            has_audio_files = [f for f in video_files if f['has_audio']]
            no_audio_files = [f for f in video_files if not f['has_audio']]
            
            if no_audio_files:
                print(f"âš ï¸  å‘çŽ° {len(no_audio_files)} ä¸ªæ— éŸ³é¢‘æ–‡ä»¶:")
                for f in no_audio_files:
                    print(f"   - {os.path.basename(f['path'])}")
            
            # å¤„ç†æ¯ä¸ªè¾“å…¥æ–‡ä»¶ï¼Œç»Ÿä¸€åˆ†è¾¨çŽ‡å’ŒéŸ³é¢‘
            processed_inputs = []
            
            for i, video_file in enumerate(video_files):
                input_stream = ffmpeg.input(video_file['path'])
                
                # å¤„ç†è§†é¢‘æµ - ç»Ÿä¸€åˆ†è¾¨çŽ‡
                video_stream = input_stream['v']
                
                # å¦‚æžœåˆ†è¾¨çŽ‡ä¸åŒ¹é…ï¼Œè¿›è¡Œç¼©æ”¾
                if video_file['width'] != target_width or video_file['height'] != target_height:
                    print(f"ðŸ“ è°ƒæ•´ {os.path.basename(video_file['path'])} åˆ†è¾¨çŽ‡: "
                          f"{video_file['width']}x{video_file['height']} -> {target_width}x{target_height}")
                    
                    # ä½¿ç”¨scale filterè¿›è¡Œç¼©æ”¾ï¼Œä¿æŒå®½é«˜æ¯”
                    video_stream = ffmpeg.filter(video_stream, 'scale', target_width, target_height, force_original_aspect_ratio='decrease')
                    video_stream = ffmpeg.filter(video_stream, 'pad', target_width, target_height, '(ow-iw)/2', '(oh-ih)/2', color='black')
                
                # å¤„ç†éŸ³é¢‘æµ
                if video_file['has_audio']:
                    audio_stream = input_stream['a']
                else:
                    # ä¸ºæ— éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆé™éŸ³
                    print(f"ðŸ”‡ ä¸º {os.path.basename(video_file['path'])} æ·»åŠ é™éŸ³è½¨é“")
                    duration = video_file['duration']
                    audio_stream = ffmpeg.input('anullsrc=channel_layout=stereo:sample_rate=44100', 
                                              f='lavfi', t=duration)['a']
                
                processed_inputs.append({'v': video_stream, 'a': audio_stream})
            
            # æ‹¼æŽ¥æ‰€æœ‰å¤„ç†è¿‡çš„æµ
            if len(has_audio_files) == 0:
                # æ‰€æœ‰æ–‡ä»¶éƒ½æ²¡æœ‰éŸ³é¢‘ï¼Œåªæ‹¼æŽ¥è§†é¢‘æµ
                print("ðŸ”‡ æ‰€æœ‰æ–‡ä»¶éƒ½æ— éŸ³é¢‘ï¼Œä»…æ‹¼æŽ¥è§†é¢‘æµ...")
                video_streams = [inp['v'] for inp in processed_inputs]
                concat_video = ffmpeg.concat(*video_streams, v=1, a=0)
                
                output_stream = ffmpeg.output(
                    concat_video, output_path,
                    vcodec='libx264', 
                    preset='medium', 
                    crf=23,
                    pix_fmt='yuv420p'
                )
            else:
                # æ‹¼æŽ¥è§†é¢‘å’ŒéŸ³é¢‘æµ
                print("ðŸ”Š æ‹¼æŽ¥è§†é¢‘å’ŒéŸ³é¢‘æµ...")
                video_streams = [inp['v'] for inp in processed_inputs]
                audio_streams = [inp['a'] for inp in processed_inputs]
                
                concat_video = ffmpeg.concat(*video_streams, v=1, a=0)
                concat_audio = ffmpeg.concat(*audio_streams, v=0, a=1)
                
                output_stream = ffmpeg.output(
                    concat_video, concat_audio, output_path,
                    vcodec='libx264', 
                    acodec='aac', 
                    preset='medium', 
                    crf=23,
                    pix_fmt='yuv420p'
                )
            
            print("âš™ï¸ æ‰§è¡Œffmpegæ‹¼æŽ¥...")
            # ç§»é™¤quiet=Trueï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            ffmpeg.run(output_stream, overwrite_output=True, quiet=False)
            print("âœ… æ‹¼æŽ¥å®Œæˆ")
            return True, ""
            
        except ffmpeg.Error as e:
            error_detail = "FFmpegæ‰§è¡Œé”™è¯¯"
            if hasattr(e, 'stderr') and e.stderr:
                try:
                    stderr_str = e.stderr.decode('utf-8') if isinstance(e.stderr, bytes) else str(e.stderr)
                    error_detail += f": {stderr_str}"
                except:
                    error_detail += f": {str(e)}"
            else:
                error_detail += f": {str(e)}"
            
            print(f"âŒ FFmpegé”™è¯¯: {error_detail}")
            return False, error_detail
            
        except Exception as e:
            error_detail = f"æ„å¤–é”™è¯¯: {str(e)}"
            print(f"âŒ æ‹¼æŽ¥å¤±è´¥: {error_detail}")
            return False, error_detail


def video_edit_flow(video_script_path: str, asset_paths: list[str], keep_video_audio: bool = False, output_dir: str = "workdir"):
    
    print("This is a new version of video_edit_flow")
    
    # 1. check if reference_script_path exists
    if not os.path.exists(video_script_path):
        raise FileNotFoundError(f"Reference script file not found: {video_script_path}")
    
    video_script = None
    with open(video_script_path, "r", encoding="utf-8") as f:
        video_script = f.read()
        
    if not video_script:
        raise ValueError(f"Failed to read video script from {video_script_path}")
    
    # 2. check if assets exist
    if not asset_paths:
        raise ValueError(f"Asset understandings are required")
    
    # 3. generate video understandings
    comprehensive_understanding_for_assets = ""
    for asset_path in asset_paths:
        if not os.path.exists(asset_path):
            print(f"âŒ Error: Asset not found: {asset_path}")
            continue
        video_understanding = understand_video_for_editor(asset_path, model_name="gemini-2.5-pro")
        video_understanding_with_asset_path = f"{asset_path}: /n {video_understanding} /n" + "="*50 + "\n"
        comprehensive_understanding_for_assets += video_understanding_with_asset_path
        
    # 4. save video understandings
    ProjectOrganizer.save(ProjectOrganizer.SaveType.UNDERSTANDINGS, comprehensive_understanding_for_assets, "comprehensive_understanding_for_assets.txt", workdir=output_dir)
    
    # 5. text based asset content selection
    user_requirements = f"Select the contents that can help me to generate a video based on the video script: {video_script}"
    text_based_asset_content_selection_path = generate_edit_instructions(comprehensive_understanding_for_assets, user_requirements)
    with open(text_based_asset_content_selection_path, "r") as f:
        text_based_asset_content_selection_str = f.read()

    text_based_asset_content_selection = json.loads(text_based_asset_content_selection_str)
    
    # 6. extract assets based on the text based asset content selection
    clip_paths_in_order = []
    for i, clip in enumerate(text_based_asset_content_selection):
        asset_path = clip["asset_path"]
        start_time = clip["start_time"]
        end_time = clip["end_time"]
        print(f"Extracting asset: {asset_path} from {start_time} to {end_time}")
        clip_path = VideoClipExtractor().execute(asset_path, start_time, end_time, clip_name=f"extracted_{i}")
        print(f"Extracted asset: {clip_path}")
        clip_paths_in_order.append(clip_path)
    
    clip_paths_in_order_json = json.dumps(clip_paths_in_order, indent=2, ensure_ascii=False)
    ProjectOrganizer.save(ProjectOrganizer.SaveType.SCRIPTS, clip_paths_in_order_json, "clip_paths_in_order.json", workdir=output_dir)
    
    # 7. concatenate the clips
    concatenated_video_path = VideoConcatenator().execute(clip_paths_in_order_json)
    print(f"Concatenated video path: {concatenated_video_path}")
    
        
    return concatenated_video_path


def generate_edit_instructions(video_understanding_text_path: str, user_requirements: str) -> str:
    with open(video_understanding_text_path, "r") as f:
        video_understanding_text = f.read()
    # Analysis prompt
    prompt = f"""
You are a professional AI video editor.

Your task: for each beat in the USER SCRIPT, select **exactly one** non-overlapping clip from the source assets in PART 2,
**in the same beat order**, with **no asset reuse**. **Do not change the original asset order**: always move forward through the
assets as they appear in PART 2; never jump back to an earlier asset.

---

## PART 2: SECOND-BY-SECOND BREAKDOWN
{video_understanding_text}

## USER SCRIPT / STRUCTURE REQUIREMENTS
{user_requirements}

---

## HARD CONSTRAINTS (must pass all):
1) One-to-one & order-locked mapping:
   - Parse the USER SCRIPT into an ordered list of beats: BEATS = [beat_1, beat_2, ..., beat_N].
   - Produce **exactly N** clips, and **clip_i corresponds to beat_i** (preserve beat order).
   - **Source-order preservation**: the chosen asset for clip_i must appear **at or after** the asset used for clip_i-1 in PART 2.
     Do **not** reorder materials and never jump back to an earlier asset.

2) Unique asset usage:
   - **Each asset_path may be used at most once** across the entire output.

3) Semantic completeness:
   - Do not cut mid-action / mid-sentence / mid-expression. Prefer natural boundaries visible in PART 2.

4) Duration alignment:
   - Each clip â‰¥ 3.0s.
   - Each clipâ€™s duration should be close to the intended duration of its beat.
   - The **total** duration should be close to the scriptâ€™s total.

5) Valid times & non-overlap:
   - start_time < end_time for every clip.
   - Times **must** be taken **only** from PART 2 (respect the second-level markers).
   - No overlaps within the selected range of any asset.

6) Tie-breaking:
   - Prefer emotionally/visually strong, clear moments most faithful to the beat.

---

## VALIDATION (self-check before you output):
- Number of output clips == number of script beats.
- Clip sequence strictly follows **beat_1 â†’ beat_2 â†’ ... â†’ beat_N**.
- **All asset_path values are unique** and follow their **original order** in PART 2 (no backward jumps).
- All time ranges are valid (numeric, â‰¥ 3.0s, within asset bounds, non-overlapping).
- Total duration â‰ˆ total intended script duration (allow a reasonable margin if needed).

---

## OUTPUT FORMAT (JSON array only, no extra text):
[
  {{
    "asset_path": "exactly-as-listed-in-PART-2",
    "start_time": 12.0,
    "end_time": 18.5,
    "description": "Briefly describe the visible moment and how it fulfills beat_i."
  }},
  ...
]

Return **only** the final JSON array of selected clips.
"""



    
    try:
        # Generate analysis
        # response = model.generate_content(prompt, request_options={'timeout': 2400})
        # result = response.text
        result = call_openai(prompt)

        # Save the result - extract only the JSON array content
        # Remove markdown code blocks and extract the JSON array
        clean_result = result.strip()
        if clean_result.startswith("```json"):
            clean_result = clean_result[7:]  # Remove ```json
        if clean_result.endswith("```"):
            clean_result = clean_result[:-3]  # Remove ```
        clean_result = clean_result.strip()
        
        # Validate JSON format
        try:
            json.loads(clean_result)
        except json.JSONDecodeError:
            print("Warning: Result is not valid JSON, saving raw result")
        
        # Save to fileï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„å¹¶è‡ªåŠ¨é€‚åº”å½“å‰è„šæœ¬ç›®å½•
        output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "workdir", "understandings")
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "selected_asset_content.json")
        with open(output_path, "w") as f:
            f.write(clean_result)
        print(f"Selected asset content saved to {output_path}")
        return output_path
        
    except Exception as e:
        error_msg = f"Error selecting content based on text understanding: {str(e)}"
        print(error_msg)
        return error_msg

class VideoEditor(Tool):
    name: str = "video_editor"
    description: str = "Edit videos and generate a concatenated video."
    parameters: dict = {
        "type": "object",
        "properties": {
            "video_script_path": {
                "type": "string",
                "description": "Path to the final video script text file",
            },
            "asset_paths": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of asset paths to be used in the video",
            },
        },
        "required": ["video_script_path", "asset_paths"],
    }

    def execute(self, video_script_path: str, asset_paths: List[str]) -> str:
        return video_edit_flow(video_script_path, asset_paths)



if __name__ == "__main__":
    with open("./workdir/understandings/comprehensive_understanding_for_assets.txt", "r") as f:
        video_understanding_text = f.read()
    with open("./new_script.txt", "r") as f:
        user_requirements = f.read()
    generate_edit_instructions(video_understanding_text, user_requirements)